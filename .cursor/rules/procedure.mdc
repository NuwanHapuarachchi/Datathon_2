---
description:# Complete Machine Learning Pipeline: From Data to Model

## *Phase 1: Data Understanding & Exploration*

### *1.1 Initial Data Assessment*
python
# Load and inspect datasets
- Load bookings.csv, tasks.csv, staffing.csv
- Check data shapes, dtypes, memory usage
- Identify unique values in key columns (task_id, section_id)
- Understand data relationships and joins


### *1.2 Exploratory Data Analysis (EDA)*
python
# Statistical Analysis
- Summary statistics for all numerical columns
- Distribution analysis (histograms, box plots)
- Correlation matrix and heatmaps
- Missing value patterns and counts

# Business Logic Understanding
- Calculate processing times: check_out_time - check_in_time
- Analyze booking patterns by date, time, task
- Examine staffing patterns across sections and dates
- Identify seasonal trends and outliers


### *1.3 Data Quality Assessment*
python
# Data Quality Checks
- Check for duplicate records
- Identify impossible values (negative times, future dates)
- Validate data consistency across linked datasets
- Document data anomalies and business rules


## *Phase 2: Data Preprocessing*

### *2.1 Data Cleaning*
python
# Handle Missing Values
- Identify missing value patterns
- Decide on imputation strategies (mean, median, forward-fill)
- Remove or flag impossible records
- Handle outliers (processing times > 8 hours, etc.)

# Data Type Corrections
- Convert date/time columns to proper datetime format
- Ensure categorical columns are properly typed
- Handle timezone issues (Asia/Colombo)


### *2.2 Feature Engineering - Temporal Features*
python
# Date/Time Decomposition
- Extract hour, day_of_week, month, quarter from timestamps
- Create cyclical encodings: sin/cos for seasonal patterns
- Add holiday flags and special day indicators
- Calculate time-based features (days_since_booking, etc.)

# Rolling and Lag Features
- Historical averages per task_id (7-day, 30-day windows)
- Seasonal decomposition components
- Trend indicators and growth rates


### *2.3 Feature Engineering - Business Logic*
python
# Task-Specific Features
- Average processing time per task_id (historical)
- Task complexity indicators (num_documents correlation)
- Queue position impact analysis
- Satisfaction rating patterns per task

# Staffing-Specific Features
- Workload ratios (total_task_time / employees_on_duty)
- Section efficiency metrics
- Capacity utilization patterns
- Peak hour indicators


### *2.4 Categorical Encoding*
python
# Handle Categorical Variables
- task_id: Keep as categorical (for CatBoost/LightGBM)
- section_id: Keep as categorical
- Alternative: Target encoding for high cardinality
- Create interaction features between categories


## *Phase 3: Data Splitting & Validation Strategy*

### *3.1 Train-Test Split*
python
# Time-Aware Splitting
- Use temporal split (not random) to avoid data leakage
- Training: Earlier dates (e.g., before 2025-06-01)
- Validation: Recent dates (e.g., 2025-06-01 to 2025-07-01)
- Test: Final period (e.g., after 2025-07-01)


### *3.2 Cross-Validation Strategy*
python
# Time Series Cross-Validation
- Use TimeSeriesSplit for proper validation
- Ensure no future data leaks into training
- Validate on multiple time periods


## *Phase 4: Model Selection & Training*

### *4.1 Baseline Models*
python
# Simple Baselines
- Mean/median prediction per task_id
- Linear regression with basic features
- Simple moving averages (for Task 2)


### *4.2 Advanced Model Training*
python
# Primary Models
Task 1: CatBoost/LightGBM for service time prediction
Task 2: CatBoost/LightGBM with time series features

# Model Training Process
- Hyperparameter tuning (GridSearch/Bayesian optimization)
- Cross-validation with proper time splits
- Feature importance analysis
- Model interpretation and validation


### *4.3 Model Ensemble (Optional)*
python
# Ensemble Strategy
- Combine CatBoost + LightGBM predictions
- Use weighted averaging or stacking
- Validate ensemble performance


## *Phase 5: Model Evaluation & Validation*

### *5.1 Performance Metrics*
python
# Regression Metrics
- RMSE (Root Mean Square Error) - primary metric
- MAE (Mean Absolute Error)
- MAPE (Mean Absolute Percentage Error)
- R² Score for explained variance

# Business Metrics
- Accuracy within ±15 minutes (Task 1)
- Staffing prediction accuracy ±1-2 employees (Task 2)


### *5.2 Model Validation*
python
# Validation Checks
- Residual analysis and error patterns
- Performance across different task_ids/sections
- Seasonal performance validation
- Edge case handling (holidays, peak periods)


## *Phase 6: Model Deployment & Inference*

### *6.1 Model Serialization*
python
# Save Models
- Export trained models (.pkl or .h5 format)
- Save preprocessing pipelines
- Document model versions and parameters


### *6.2 Inference Pipeline*
python
# Create Prediction Functions
- Load saved models and preprocessors
- Implement prediction functions for both tasks
- Handle edge cases and validation in production
- Create clear input/output demonstrations


## *Phase 7: Documentation & Deliverables*

### *7.1 Code Documentation*
python
# Notebook Structure
- Keep all preprocessing, training, evaluation cells
- Add clear markdown explanations
- Include final inference demonstration cell
- Ensure reproducibility with random seeds


### *7.2 Model Documentation*
python
# Technical Documentation
- Architecture diagrams
- Feature engineering rationale
- Model selection reasoning
- Performance analysis and insights


## *Recommended Tools & Libraries*

python
# Essential Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import TimeSeriesSplit, train_test_split

# Models
import lightgbm as lgb
import catboost as cb
from sklearn.ensemble import RandomForestRegressor

# Evaluation
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Visualization
import plotly.express as px
import plotly.graph_objects as go


## *Timeline Recommendation*

| Phase | Time Allocation | Priority |
|-------|----------------|----------|
| Data Understanding & EDA | 20% | High |
| Feature Engineering | 25% | Critical |
| Model Training & Tuning | 30% | Critical |
| Validation & Testing | 15% | High |
| Documentation & Delivery | 10% | Medium |

This systematic approach ensures you build a robust, well-documented model that performs well on both tasks while meeting all competition requirements.

Would you like me to dive deeper into any specific phase or create code templates for particular sections?
globs:
alwaysApply: True
---
